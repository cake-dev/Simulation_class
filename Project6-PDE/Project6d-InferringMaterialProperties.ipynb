{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d38b89d",
   "metadata": {},
   "source": [
    "# Project 6d - Inferring Material Properties\n",
    "As we have seen before, it's often the case that we would like to model a system without having full knowledge of the properties of that system, and that such properties will need to be inferred from data.  That is very often true of partial differential equations of many types.  \n",
    "\n",
    "Take the following as an example: we would like to know the thermal diffusivity $k$ of some new material.  Our testing apparatus is such that we can specify the temperature at one end (a Dirichlet boundary condition of, say, $u(x=0,t) = 1$, and we can perfectly insulate the other end (the Neumann condition $\\frac{\\partial u}{\\partial x}\\left(x=1,t\\right) = 0$).  We measure the temperature (with a normally-distributed error of $\\sigma=0.05$) at the insulated boundary at $t=5$ and find it to be $u_{obs}(x=1,t=5) = 0.63$.  What potential thermal diffusivities are compatible with this observation?  \n",
    "\n",
    "**Adapt the MCMC procedure that we used to calibrate SIR models to answer this question.**  Note that I have reproduced the Metropolis algorithm class and the SIR likelihood class to serve as a starting point.  Note that you will *not* need to modify the Metropolis class, but you *will* need to modify the SIR class to work with your diffusion equation solver instead, and to represent the observation scenario described above.  It is worth mentioning that you will have to run the diffusion solver to $t=5$ many times (on the order of tens of thousands of runs) with many different possible diffusivities.  As such, it will behoove you to use the largest time step (and $\\Delta x$) that you can that is still accurate.  I encourage you to use backward Euler - however you should compare computed solutions at the final time for different time steps (for some assumed $k$ and outside the framework of MCMC) to see how big a time step you can use while still getting accurate results.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b28cbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ode_methods as om\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Diffusion:\n",
    "    def __init__(self, nx, dx, k=0.01):\n",
    "        self.nx = nx\n",
    "        self.dx = dx\n",
    "        self.k = k\n",
    "        self.A = self.create_matrix()\n",
    "    \n",
    "    def create_matrix(self):\n",
    "        A = np.zeros((self.nx, self.nx))\n",
    "        for i in range(1, self.nx - 1): # Interior points\n",
    "            # here we use k directly, while in the explicit method we used 1, -2, 1 and then multiplied by k in the right hand side\n",
    "            A[i, i - 1] = self.k\n",
    "            A[i, i] = -2 * self.k\n",
    "            A[i, i + 1] = self.k\n",
    "        A /= self.dx**2 # Normalizing by dx^2\n",
    "        return A\n",
    "    \n",
    "    def stiffness_matrix(self, dt):\n",
    "        # Stiffness matrix for Backward Euler\n",
    "        I = np.identity(self.nx)\n",
    "        return I / dt - self.A\n",
    "    \n",
    "    def load_vector(self, u, dt):\n",
    "        # Load vector for Backward Euler\n",
    "        return u / dt\n",
    "    \n",
    "class BackwardEuler:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def step(self, ode, t, dt, u_0):\n",
    "        # Compute the matrix L and vector f for the linear system L*u_{t+1} = f\n",
    "        L = ode.stiffness_matrix(dt)\n",
    "        f = ode.load_vector(u_0, dt)\n",
    "        # Solve the linear system\n",
    "        return np.linalg.solve(L, f)\n",
    "    \n",
    "def diffuImplicit(_k=0.01, _dt=0.05, _t_span=(0,50)):\n",
    "    # Setup\n",
    "    L = 1.0  # Length of the domain\n",
    "    nx = 100  # Number of grid points\n",
    "    dx = L / (nx - 1)  # Grid spacing\n",
    "    x = np.linspace(0, L, nx)  # Position array\n",
    "    u0 = np.zeros(nx)  # Initial condition array\n",
    "    u0[0] = 1\n",
    "\n",
    "    # Parameters\n",
    "    k = _k  # Diffusion coefficient\n",
    "    dt = _dt  # Time step\n",
    "    t_span = _t_span  # Time span\n",
    "\n",
    "    # Setup model and solver\n",
    "    ode = Diffusion(nx, dx, k)\n",
    "    method = BackwardEuler()\n",
    "    integrator = om.Integrator(ode, method)\n",
    "    t, u = integrator.integrate(t_span, dt, u0)\n",
    "\n",
    "    # Visualization\n",
    "    cmap = plt.cm.viridis\n",
    "    for tt, uu in zip(t[::10], u[::10]): # Plot every 10th solution\n",
    "        plt.plot(x, uu, color=cmap(tt/t[-1]))\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"u(x,t)\")\n",
    "    plt.title(\"Diffusion using Backward Euler\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb0b9d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ode_methods as om\n",
    "\n",
    "class Metropolis:\n",
    "    def __init__(self):\n",
    "        # Initialize chains \n",
    "        self.P_chain = []\n",
    "        self.m_chain = []\n",
    "        \n",
    "    def sample(self,m_0,log_posterior,h,n_samples,burnin=0,thin_factor=1):\n",
    "        # Compute initial unscaled log-posterior\n",
    "        P_0 = log_posterior(m_0)\n",
    "        \n",
    "        # Add initial location and posterior to the chain\n",
    "        self.P_chain.append(P_0)\n",
    "        self.m_chain.append(m_0)\n",
    "        n = len(m_0)\n",
    "\n",
    "        # Draw samples\n",
    "        for i in range(n_samples):\n",
    "\n",
    "\n",
    "            # Propose new value\n",
    "            m_prime = m_0 + np.random.randn(n)*h\n",
    "\n",
    "            # Compute new unscaled log-posterior\n",
    "            P_1 = log_posterior(m_prime)\n",
    "            \n",
    "            # Compute logarithm of probability ratio\n",
    "            log_ratio = P_1 - P_0\n",
    "            \n",
    "            # Convert to non-log space\n",
    "            ratio = np.exp(log_ratio)\n",
    "            \n",
    "            # If proposed value is more probable than current value, accept.  \n",
    "            # If not, then accept proportional to the probability ratios\n",
    "            if ratio>np.random.rand():\n",
    "                m_0 = m_prime\n",
    "                P_0 = P_1\n",
    "                \n",
    "            # Only append to the chain if we're past burn-in. \n",
    "            if i>burnin:\n",
    "                # Only append every j-th sample to the chain\n",
    "                if i%thin_factor==0:\n",
    "                    self.P_chain.append(P_0)\n",
    "                    self.m_chain.append(m_0)\n",
    "            \n",
    "            if i%100==0:\n",
    "                print(i, P_1)\n",
    "                    \n",
    "        return np.array(self.P_chain),np.array(self.m_chain)\n",
    "\n",
    "# Instantiate sampler\n",
    "sampler = Metropolis()\n",
    "    \n",
    "class DiffusionPosterior:\n",
    "    def __init__(self,t_obs,u_obs,sigma2_obs):\n",
    "        self.u_obs = u_obs\n",
    "        self.t_obs = t_obs\n",
    "        self.sigma2_obs = sigma2_obs\n",
    "        \n",
    "    def log_posterior(self,log_m):\n",
    "        # We have defined our parameters to sample over as the logarithm\n",
    "        # of the model parameters.  Here we exponentiate them to get\n",
    "        # the representation that we need.  \n",
    "        m = np.exp(log_m)\n",
    "        k = m[0] \n",
    "        dt = m[1]\n",
    "        nx = 100\n",
    "        dx = 1/(nx-1)\n",
    "        t_span = (0,10)\n",
    "        \n",
    "        u0 = np.zeros(nx)\n",
    "        u0[0] = 1\n",
    "\n",
    "        ode = Diffusion(nx, dx, k)\n",
    "        method = BackwardEuler()\n",
    "        integrator = om.Integrator(ode, method)\n",
    "        t, u = integrator.integrate(t_span, dt, u0)\n",
    "        P = -0.5*np.sum((self.u_obs - u)**2)/self.sigma2_obs\n",
    "        return P"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa635e7",
   "metadata": {},
   "source": [
    "**Find a way to visualize the distribution of $k$ values.  Verify that these are sensible solutions by running the model forward with these values and ensuring that they match the observations consistent with the stated errors.**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53c83e25",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3379792433.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[7], line 7\u001b[1;36m\u001b[0m\n\u001b[1;33m    plt.hist(m_chain[,:0],bins=50) # Plot the posteriors for k\u001b[0m\n\u001b[1;37m                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "temp_obs = 0.63 # u(x=1,t=5)\n",
    "t_obs = 5 # t=5\n",
    "sigma2_obs = 0.05**2 # sigma=0.05\n",
    "diffusion_posterior = DiffusionPosterior(t_obs,temp_obs,sigma2_obs) # Instantiate the posterior\n",
    "log_m = np.log(np.array([0.01,0.05])) # Initial guess for k and dt\n",
    "P_chain,m_chain = sampler.sample(log_m,diffusion_posterior.log_posterior,0.01,10000,burnin=1000,thin_factor=10) # Sample the posterior\n",
    "plt.hist(m_chain,bins=50) # Plot the posteriors for k\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Posterior Density\")\n",
    "plt.title(\"Posterior Distribution of k\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
